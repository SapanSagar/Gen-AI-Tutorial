{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A placeholder GPT model architecture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    " \"vocab_size\": 50257,  # Vocabulary size\n",
    " \"context_length\": 1024,  # Context length\n",
    " \"emb_dim\": 768,   # Embedding dimension    \n",
    "\"n_heads\": 12,   # Number of attention heads     \n",
    "\"n_layers\": 12,   # Number of layers    \n",
    "\"drop_rate\": 0.1,   # Dropout rate  \n",
    "\"qkv_bias\": False    # Query-Key-Value bias  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]) #\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"]) #B\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    " \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    " \n",
    "class DummyTransformerBlock(nn.Module): #C\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    " \n",
    "    def forward(self, x): #D\n",
    "        return x\n",
    " \n",
    "class DummyLayerNorm(nn.Module): #E\n",
    "    def __init__(self, normalized_shape, eps=1e-5): #F\n",
    "        super().__init__()\n",
    " \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6755, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM ARCHITECTURE : LAYER NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Explanation with a simple example\n",
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5) #A\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [5.9605e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-2.9802e-08],\n",
      "        [ 0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE: FEEDFORWARD NEURAL NETWORK WITH GELU ACTIVATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the GELU activation function approximation used by GPT-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use the GELU function to implement the small neural network module,\n",
    "FeedForward, that we will be using in the LLM's transformer block later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    " \"vocab_size\": 50257,  # Vocabulary size\n",
    " \"context_length\": 1024,  # Context length\n",
    " \"emb_dim\": 768,   # Embedding dimension    \n",
    "\"n_heads\": 12,   # Number of attention heads     \n",
    "\"n_layers\": 12,   # Number of layers    \n",
    "\"drop_rate\": 0.1,   # Dropout rate  \n",
    "\"qkv_bias\": False    # Query-Key-Value bias  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE: SHORTCUT CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how we can add shortcut connections to the forward method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[2., 1., -2.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement a function that computes the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00030619598692283034\n",
      "layers.1.0.weight has gradient mean of 0.0001315188710577786\n",
      "layers.2.0.weight has gradient mean of 0.0005546467727981508\n",
      "layers.3.0.weight has gradient mean of 0.0014715546276420355\n",
      "layers.4.0.weight has gradient mean of 0.0053015160374343395\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 2.0485668182373047\n",
      "layers.1.0.weight has gradient mean of 0.46502214670181274\n",
      "layers.2.0.weight has gradient mean of 3.061903953552246\n",
      "layers.3.0.weight has gradient mean of 2.2600228786468506\n",
      "layers.4.0.weight has gradient mean of 10.654751777648926\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    " \"vocab_size\": 50257,  # Vocabulary size\n",
    " \"context_length\": 1024,  # Context length\n",
    " \"emb_dim\": 768,   # Embedding dimension    \n",
    "\"n_heads\": 12,   # Number of attention heads     \n",
    "\"n_layers\": 12,   # Number of layers    \n",
    "\"drop_rate\": 0.1,   # Dropout rate  \n",
    "\"qkv_bias\": False    # Query-Key-Value bias  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4223, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATING TEXT FROM OUTPUT TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() #disable random components like dropout\n",
    "out = generate_text_simple(\n",
    "model=model,\n",
    "idx=encoded_tensor,\n",
    "max_new_tokens=6,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy FUnction\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Entire LLM Pretraining Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Training completed in 774.16 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECODING STRATEGY : TEMPERATURE SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETS ASSUME llm generates below logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits2 = next_token_logits/0.1\n",
    "\n",
    "next_token_logits3 = next_token_logits/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
      "        2.9718e-38, 9.0133e-03, 2.8514e-22])\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits2, dim=0)\n",
    "\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits3, dim=0)\n",
    "\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        \n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you knew subsystem able mas only eachrs melancholy extract cf beneficiaries Renaissance blocked the CLA\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    \n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
